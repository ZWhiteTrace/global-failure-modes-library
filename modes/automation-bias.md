# Automation Bias

Over-reliance on automated systems, leading to uncritical acceptance of their outputs.

## Warning Signs

- [ ] AI/automated suggestions accepted without verification
- [ ] Manual checks skipped "because the system handles it"
- [ ] Alerts dismissed as false positives without investigation
- [ ] Human expertise atrophied due to automation dependency

## Real-World Examples

**Aviation**: Pilots over-trusting autopilot, failing to notice system errors until too late.

**Healthcare**: Doctors accepting diagnostic AI recommendations without clinical judgment.

**Software**: Developers merging AI-generated code without understanding it.

## Mitigation Checklist

1. **Verify Before Trust**: Always spot-check automated outputs
2. **Maintain Skills**: Regular practice of manual procedures
3. **Question Defaults**: "Why did the system suggest this?"
4. **Document Overrides**: Track when humans override automation and why

## Code Review Questions

- Is there a human verification step for critical automated decisions?
- Can operators understand and explain automated outputs?
- Are there fallback procedures when automation fails?

## Related Modes

- [Responsibility Laundering](./responsibility-laundering.md)
